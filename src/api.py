"""
API REST FastAPI pour le service de pr√©diction.
"""

# Imports standard de Python
import os
import json
import time
import uuid
import asyncio
import pickle
import tempfile
import functools
from datetime import datetime
from contextlib import asynccontextmanager
from typing import List, Dict, Optional, Any, Callable, Union

# Imports de biblioth√®ques externes
import numpy as np
import pandas as pd
import mlflow
import mlflow.keras
import mlflow.tensorflow
from fastapi import FastAPI, HTTPException, UploadFile, File, Form, Body, Query, Request, Path
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from tensorflow.keras.models import load_model

# Imports des modules locaux
from src.predict import PredictionService
from src.data_ingestion import DataIngestionPipeline
from src.logger_config import init_logging
from src.utils import (
    get_mlflow_client, 
    get_latest_model_version,
    load_model_from_registry, 
    get_vectorizer_from_run
)
from src.config import (
    MODEL_NAME,
    MODEL_PATH,
    VECTORIZER_PATH,
    MLFLOW_TRACKING_URI
)

# Import des modules de validation et d'entra√Ænement (utilis√©s plus tard)
from src.model_validation import validate_model, validate_and_promote_model
from src.train import train_model as train_model_function

# Initialisation du syst√®me de logging
loggers = init_logging(api=True)
logger = loggers['api']

# Fonction de d√©corateur pour logger les appels d'API
def log_endpoint(func: Callable):
    @functools.wraps(func)
    async def wrapper(*args, request = None, **kwargs):
        # G√©n√©ration d'un identifiant unique pour la requ√™te
        request_id = str(uuid.uuid4())[:8]
        
        # Extraction des donn√©es de la requ√™te pour le logging
        # V√©rifier si l'objet request a les attributs attendus d'une requ√™te FastAPI
        has_client = hasattr(request, 'client') and request.client is not None
        has_url = hasattr(request, 'url') and request.url is not None
        has_method = hasattr(request, 'method')
        
        client_host = request.client.host if has_client else "unknown"
        endpoint = request.url.path if has_url else func.__name__
        method = request.method if has_method else "UNKNOWN"
        
        # Log de d√©but de requ√™te (format standard)
        logger.info(f"[{request_id}] D√©but de traitement: {endpoint} - Client: {client_host}")
        
        # Mesure du temps d'ex√©cution
        start_time = time.time()
        
        try:
            # Ex√©cution de la fonction d'origine
            response = await func(*args, **kwargs) if asyncio.iscoroutinefunction(func) else func(*args, **kwargs)
            
            # Calcul du temps d'ex√©cution
            execution_time = time.time() - start_time
            
            # Log de fin de requ√™te r√©ussie (avec attributs HTTP)
            if request:
                status_code = getattr(response, "status_code", 200)
                logger.info(
                    f"Endpoint trait√© - {request_id}",
                    extra={
                        'method': method,
                        'url': endpoint,
                        'status_code': status_code,
                        'response_time': execution_time,
                        'client_ip': client_host
                    }
                )
            else:
                # Format standard si pas de requ√™te
                logger.info(f"[{request_id}] Traitement r√©ussi: {func.__name__} - Temps: {execution_time:.3f}s")
            
            return response
            
        except Exception as e:
            # Calcul du temps d'ex√©cution en cas d'erreur
            execution_time = time.time() - start_time
            
            # Log de l'erreur (format standard)
            logger.error(f"[{request_id}] Erreur lors du traitement de {endpoint} - {str(e)} - Temps: {execution_time:.3f}s", exc_info=True)
            
            # Relance de l'exception pour que FastAPI puisse la g√©rer
            raise
            
    return wrapper

# Cr√©ation d'une classe middleware pour le logging
class LoggingMiddleware:
    def __init__(self, app):
        self.app = app
        
    async def __call__(self, scope, receive, send):
        if scope["type"] != "http":
            return await self.app(scope, receive, send)
            
        # Cr√©ation d'un ID de requ√™te unique
        request_id = str(uuid.uuid4())[:8]
        
        # Extraction des informations de la requ√™te
        method = scope.get("method", "UNKNOWN")
        path = scope.get("path", "UNKNOWN")
        client = scope.get("client", ("UNKNOWN", 0))
        client_ip = client[0] if client else "UNKNOWN"
        
        # Log de d√©but de requ√™te (format standard pour √©viter l'utilisation des attributs sp√©ciaux)
        logger.info(f"[{request_id}] Requ√™te re√ßue: {method} {path} - Client: {client_ip}")
        
        # Mesure du temps d'ex√©cution
        start_time = time.time()
        
        # Traitement de la requ√™te
        await self.app(scope, receive, send)
        
        # Calcul du temps d'ex√©cution
        execution_time = time.time() - start_time
        
        # Log de fin de requ√™te avec les attributs HTTP pour le formateur sp√©cial
        logger.info(
            f"Requ√™te termin√©e - {request_id}",
            extra={
                'method': method,
                'url': path,
                'status_code': "200",  # Nous n'avons pas acc√®s au code de statut ici
                'response_time': execution_time,
                'client_ip': client_ip
            }
        )
@asynccontextmanager
async def lifespan(app: FastAPI):
    """√âv√©nement ex√©cut√© au d√©marrage de l'application"""
    logger.info("Initialisation de l'application...")
    init_mlflow_model()
    logger.info("Initialisation termin√©e")
    yield
    logger.info("Arr√™t de l'application")

app = FastAPI(
    title="Datascientest MLOps Analyse de Sentiments",
    description="""
    # API pour l'analyse de sentiments des avis clients
    
    Cette API permet de :
    * **Pr√©dire** le sentiment (positif/n√©gatif) d'un texte
    * **Charger** et traiter des fichiers CSV d'avis clients
    * **Entra√Æner** de nouveaux mod√®les √† partir des donn√©es
    
    ## üöÄ Guide d'utilisation rapide:
    
    1. Pour la **pr√©diction** de sentiment:
       - Endpoint JSON standard: `/predict`
       - Endpoint formulaire: `/predict/form` ‚úÖ (recommand√© pour les tests, pr√©-rempli avec exemple)
    
    2. Pour **l'entra√Ænement** du mod√®le:
       - Endpoint JSON standard: `/train`
       - Endpoint formulaire: `/train/form` ‚úÖ (recommand√© pour les tests, tous les champs optionnels)
    
    3. Pour **l'upload** de donn√©es:
       - Endpoint: `/upload` (accepte un fichier CSV)
    
    Les formulaires sont pr√©-remplis avec des valeurs par d√©faut pour faciliter les tests.
    
    D√©velopp√© dans le cadre du projet MLOps Datascientest.
    """,
    version="1.0.0",
    lifespan=lifespan,
    openapi_tags=[
        {
            "name": "G√©n√©ral",
            "description": "Informations g√©n√©rales sur l'API"
        },
        {
            "name": "Pr√©diction",
            "description": "Endpoints pour la pr√©diction de sentiments (formats JSON et formulaire)"
        },
        {
            "name": "Donn√©es",
            "description": "Endpoints pour le chargement et la gestion des donn√©es"
        },
        {
            "name": "Entra√Ænement",
            "description": "Endpoints pour l'entra√Ænement de mod√®les (formats JSON et formulaire)"
        }
    ]
)

# Ajout du middleware de logging
app.add_middleware(LoggingMiddleware)
logger.info("API d√©marr√©e avec middleware de logging activ√©")

# Initialisation lazy du service de pr√©diction et du vectorizer
prediction_service = None
vectorizer = None

def load_vectorizer():
    """Charge le vectorizer depuis le fichier local"""
    global vectorizer
    if vectorizer is None:
        logger.info(f"Chargement du vectorizer depuis {VECTORIZER_PATH}")
        try:
            with open(VECTORIZER_PATH, 'rb') as f:
                vectorizer = pickle.load(f)
            logger.info("Vectorizer charg√© avec succ√®s")
        except Exception as e:
            logger.error(f"Erreur lors du chargement du vectorizer: {str(e)}", exc_info=True)
            raise
    else:
        logger.debug("Utilisation du vectorizer en cache")
    return vectorizer

def init_mlflow_model():
    """
    Initialise le mod√®le dans MLflow Model Registry si n√©cessaire.
    Cr√©e une premi√®re version √† partir du mod√®le local si aucune version n'existe.
    """
    logger.info("Initialisation du mod√®le MLflow")

    # Cr√©ation du client MLflow configur√© pour S3/MinIO
    client = get_mlflow_client()
    
    try:
        # V√©rifier si le mod√®le existe dans le registre
        try:
            model = client.get_registered_model(MODEL_NAME)
            logger.info(f"Mod√®le {MODEL_NAME} trouv√© dans le registre MLflow")
        except:
            logger.info(f"Cr√©ation du mod√®le {MODEL_NAME} dans MLflow Model Registry")
            client.create_registered_model(MODEL_NAME)
            logger.info(f"Mod√®le {MODEL_NAME} cr√©√© avec succ√®s")
        
        # V√©rifier s'il existe des versions
        try:
            latest_version = get_latest_model_version(client, MODEL_NAME)
            logger.info(f"Version existante trouv√©e: {latest_version.version}")
        except ValueError:
            logger.info("Aucune version trouv√©e. Cr√©ation de la version initiale...")
            # S'assurer que l'exp√©rience existe avant de d√©marrer le run
            # Le client MLflow est d√©j√† configur√© pour S3/MinIO par get_mlflow_client
            mlflow.set_experiment("model_training")
            experiment = mlflow.get_experiment_by_name("model_training")
            artifact_uri = f"http://mlflow:5000/artifacts/{experiment.experiment_id}"
            # Cr√©er un run MLflow pour enregistrer le mod√®le initial
            with mlflow.start_run(run_name="initial_model_registration") as run:
                client.set_tag(run.info.run_id, "mlflow.artifact.uri", artifact_uri)
                logger.info(f"D√©marrage d'un run MLflow (ID: {run.info.run_id})")
                try:
                    # Charger le mod√®le directement comme un mod√®le Keras
                    logger.info(f"Tentative de chargement du mod√®le depuis {MODEL_PATH}")
                    model = load_model(MODEL_PATH)
                    logger.info("Mod√®le Keras charg√© avec succ√®s")
                except Exception as e:
                    logger.warning(f"Erreur lors du chargement du mod√®le comme mod√®le Keras: {str(e)}")
                    logger.info("Tentative de chargement comme mod√®le pickle...")
                    with open(MODEL_PATH, 'rb') as f:
                        model = pickle.load(f)
                    logger.info("Mod√®le pickle charg√© avec succ√®s")
                
                # Charger le vectorizer
                logger.info(f"Chargement du vectorizer depuis {VECTORIZER_PATH}")
                with open(VECTORIZER_PATH, 'rb') as f:
                    vectorizer = pickle.load(f)
                logger.info("Vectorizer charg√© avec succ√®s")
                
                # Log du vectorizer comme artifact (MLflow se charge de le copier dans son artifact store)
                logger.info("Enregistrement du vectorizer comme artifact MLflow")
                try:
                    # Utiliser directement le chemin du vectorizer local sans cr√©er de fichier temporaire
                    mlflow.log_artifact(VECTORIZER_PATH, "vectorizer")
                    logger.info("Vectorizer enregistr√© avec succ√®s comme artifact MLflow")
                except Exception as e:
                    logger.warning(f"Erreur lors de l'enregistrement du vectorizer comme artifact: {str(e)}")
                    logger.warning("Continuons avec le log du mod√®le sans l'artifact vectorizer")
                
                # Log du mod√®le avec MLflow, en sp√©cifiant explicitement keras comme flavor
                logger.info("Enregistrement du mod√®le dans MLflow")
                
                # Fallback √† la m√©thode standard si la premi√®re √©choue
                mlflow.tensorflow.log_model(
                    model,
                    artifact_path="model",
                    registered_model_name=MODEL_NAME
                )
                logger.info(f"Mod√®le enregistr√© avec succ√®s (m√©thode standard): {MODEL_NAME}")
            
                # R√©cup√©rer la derni√®re version cr√©√©e
                latest_versions = client.search_model_versions(f"name='{MODEL_NAME}'")
                if latest_versions:
                    latest_version = latest_versions[0]
                    # Mettre le tag "production" pour la version initiale
                    logger.info(f"Application du tag 'production' pour la version {latest_version.version}")
                    client.transition_model_version_stage(
                        name=MODEL_NAME,
                        version=latest_version.version,
                        stage="Production"
                    )
                    logger.info(f"Version {latest_version.version} marqu√©e comme 'Production'")
                    
            logger.info("Version initiale cr√©√©e avec succ√®s")
            
    except Exception as e:
        logger.error(f"Erreur lors de l'initialisation du mod√®le dans MLflow: {str(e)}", exc_info=True)
        raise

def get_prediction_service(model_name: Optional[str] = None, model_version: Optional[str] = None):
    """
    Retourne une instance du service de pr√©diction.
    
    Args:
        model_name: Nom du mod√®le √† utiliser. Si None, utilise MODEL_NAME de la configuration
        model_version: Version sp√©cifique du mod√®le. Si None, utilise la derni√®re version disponible
        
    Returns:
        PredictionService: Instance du service de pr√©diction
    """
    global prediction_service
    
    # Si un mod√®le sp√©cifique est demand√©, ne pas utiliser le cache
    if model_name or model_version:
        logger.info(f"Chargement d'un mod√®le sp√©cifique: {model_name or MODEL_NAME}, version: {model_version or 'latest'}")
        # Configuration du client MLflow configur√© pour S3/MinIO
        
        # Chargement du mod√®le depuis MLflow
        client = get_mlflow_client()
        logger.info(f"Chargement du mod√®le depuis le registre MLflow: {model_name or MODEL_NAME}, version: {model_version or 'latest'}")
        model = load_model_from_registry(model_name or MODEL_NAME, version=model_version)
        logger.info("Mod√®le charg√© avec succ√®s")
        
        # Utilisation du vectorizer local
        logger.info("Chargement du vectorizer local")
        vectorizer = load_vectorizer()
        
        logger.info("Cr√©ation du service de pr√©diction avec mod√®le et vectorizer")
        return PredictionService.from_artifacts(
            model=model,
            vectorizer=vectorizer
        )
        
    # Utiliser le cache si aucun mod√®le sp√©cifique n'est demand√©
    if prediction_service is None:
        logger.info(f"Initialisation du service de pr√©diction avec le mod√®le par d√©faut: {MODEL_NAME}")
        
        # R√©cup√©ration de la derni√®re version du mod√®le avec le client configur√© pour S3/MinIO
        client = get_mlflow_client()
        latest_version = get_latest_model_version(client, MODEL_NAME)
        logger.info(f"Chargement du mod√®le version: {latest_version.version}")
        
        # Chargement du mod√®le depuis MLflow
        model = load_model_from_registry(MODEL_NAME)
        logger.info("Mod√®le charg√© avec succ√®s")
        
        # Utilisation du vectorizer local
        logger.info("Chargement du vectorizer local")
        vectorizer = load_vectorizer()
        
        # Cr√©ation du service avec le mod√®le et le vectorizer
        logger.info("Cr√©ation du service de pr√©diction avec mod√®le et vectorizer")
        prediction_service = PredictionService.from_artifacts(
            model=model,
            vectorizer=vectorizer
        )
        logger.info("Service de pr√©diction initialis√© avec succ√®s")
    else:
        logger.info("Utilisation du service de pr√©diction en cache")
        
    return prediction_service

class PredictionRequest(BaseModel):
    """Mod√®le pour une requ√™te de pr√©diction de sentiment"""
    text: str = Field(
        ..., 
        title="Texte √† analyser", 
        description="Le texte de l'avis client pour lequel vous souhaitez pr√©dire le sentiment",
        example="Ce produit est vraiment excellent, je le recommande vivement !"
    )
    model_name: Optional[str] = Field(
        None, 
        title="Nom du mod√®le", 
        description="Nom du mod√®le √† utiliser pour la pr√©diction (optionnel)",
        example="dst_trustpilot"
    )
    model_version: Optional[str] = Field(
        None, 
        title="Version du mod√®le", 
        description="Version sp√©cifique du mod√®le √† utiliser (optionnel)",
        example="1"
    )
    
    class Config:
        schema_extra = {
            "example": {
                "text": "Ce produit est vraiment excellent, je le recommande vivement !",
                "model_name": "dst_trustpilot",
                "model_version": "1"
            }
        }

class PredictionResponse(BaseModel):
    """R√©ponse de pr√©diction de sentiment"""
    prediction: int = Field(
        ..., 
        title="Pr√©diction", 
        description="0 pour sentiment n√©gatif, 1 pour sentiment positif",
        example=1
    )
    probabilities: Dict[str, float] = Field(
        ..., 
        title="Probabilit√©s", 
        description="Probabilit√©s pour chaque classe (n√©gatif et positif)",
        example={"n√©gatif": 0.1, "positif": 0.9}
    )
    sentiment: str = Field(
        ..., 
        title="Sentiment", 
        description="Sentiment en texte: 'n√©gatif' ou 'positif'",
        example="positif"
    )

class TrainingRequest(BaseModel):
    """Mod√®le pour une requ√™te d'entra√Ænement"""
    run_id: Optional[str] = Field(
        None, 
        title="ID du run MLflow", 
        description="ID du run MLflow contenant les donn√©es d'entra√Ænement (optionnel)",
        example="a1b2c3d4e5f6"
    )
    model_name: Optional[str] = Field(
        None, 
        title="Nom du mod√®le", 
        description="Nom sous lequel enregistrer le nouveau mod√®le (optionnel)",
        example="mon_nouveau_modele"
    )
    base_model_name: Optional[str] = Field(
        None, 
        title="Nom du mod√®le de base", 
        description="Nom du mod√®le √† utiliser comme base (optionnel)",
        example="dst_trustpilot"
    )
    base_model_version: Optional[str] = Field(
        None, 
        title="Version du mod√®le de base", 
        description="Version du mod√®le de base √† utiliser (optionnel)",
        example="1"
    )
    
    class Config:
        schema_extra = {
            "example": {
                "run_id": "a1b2c3d4e5f6",
                "model_name": "mon_nouveau_modele",
                "base_model_name": "dst_trustpilot",
                "base_model_version": "1"
            }
        }

class TrainingResponse(BaseModel):
    """R√©ponse d'entra√Ænement du mod√®le"""
    status: str = Field(
        ..., 
        title="Statut", 
        description="Statut de la requ√™te d'entra√Ænement",
        example="success"
    )
    metrics: Dict[str, float] = Field(
        ..., 
        title="M√©triques", 
        description="M√©triques d'entra√Ænement et d'√©valuation",
        example={"train_accuracy": 0.85, "test_accuracy": 0.82}
    )
    run_id: str = Field(
        ..., 
        title="ID du run MLflow", 
        description="ID du run MLflow d'entra√Ænement",
        example="a1b2c3d4e5f6"
    )
    data_path: str = Field(
        ..., 
        title="Chemin des donn√©es", 
        description="Chemin vers les donn√©es utilis√©es pour l'entra√Ænement",
        example="data/processed/processed_data_20250723_120000.csv"
    )
    message: str = Field(
        ..., 
        title="Message", 
        description="Message d√©crivant le r√©sultat de l'entra√Ænement",
        example="Mod√®le entra√Æn√© avec succ√®s"
    )
    model_name: str = Field(
        ..., 
        title="Nom du mod√®le", 
        description="Nom du mod√®le enregistr√©",
        example="dst_trustpilot"
    )
    model_version: str = Field(
        ..., 
        title="Version du mod√®le", 
        description="Version du mod√®le enregistr√©",
        example="2"
    )

class IngestionResponse(BaseModel):
    """R√©ponse d'ingestion des donn√©es"""
    status: str = Field(
        ..., 
        title="Statut", 
        description="Statut de la requ√™te d'ingestion",
        example="success"
    )
    n_processed_rows: int = Field(
        ..., 
        title="Nombre de lignes trait√©es", 
        description="Nombre de lignes trait√©es et conserv√©es",
        example=1000
    )
    stats: Dict = Field(
        ..., 
        title="Statistiques", 
        description="Statistiques sur les donn√©es trait√©es",
        example={
            "n_rows": 1000, 
            "n_missing_avis": 0, 
            "n_missing_notes": 0, 
            "avg_note": 4.2, 
            "min_note": 1, 
            "max_note": 5,
            "avg_avis_length": 120.5
        }
    )
    saved_path: Optional[str] = Field(
        None,
        title="Chemin de sauvegarde",
        description="Chemin o√π les donn√©es trait√©es ont √©t√© sauvegard√©es",
        example="data/processed/processed_data_20250721_001436.csv"
    )
    
class ValidationRequest(BaseModel):
    """Mod√®le pour une requ√™te de validation de mod√®le"""
    model_name: Optional[str] = Field(
        None, 
        title="Nom du mod√®le", 
        description="Nom du mod√®le √† valider (optionnel, tous les mod√®les en attente si non sp√©cifi√©)",
        example="dst_trustpilot"
    )
    model_version: Optional[str] = Field(
        None, 
        title="Version du mod√®le", 
        description="Version du mod√®le √† valider (obligatoire si model_name est sp√©cifi√©)",
        example="2"
    )
    auto_approve: bool = Field(
        False, 
        title="Approbation automatique", 
        description="Si True, le mod√®le sera automatiquement promu en production s'il passe la validation",
        example=False
    )
    threshold: Optional[float] = Field(
        None, 
        title="Seuil de validation", 
        description="Seuil d'accuracy pour consid√©rer le mod√®le comme valid√© (utilise la valeur de configuration par d√©faut)",
        example=0.75
    )
    
    class Config:
        schema_extra = {
            "example": {
                "model_name": "dst_trustpilot",
                "model_version": "2",
                "auto_approve": True,
                "threshold": 0.75
            }
        }
    
class ValidationResponse(BaseModel):
    """R√©ponse de validation de mod√®le"""
    status: str = Field(
        ..., 
        title="Statut", 
        description="Statut de la requ√™te de validation",
        example="success"
    )
    validation_id: str = Field(
        ..., 
        title="ID de validation", 
        description="Identifiant unique de cette session de validation",
        example="a1b2c3d4"
    )
    models_validated: int = Field(
        ..., 
        title="Nombre de mod√®les valid√©s", 
        description="Nombre de mod√®les √©valu√©s pendant cette validation",
        example=1
    )
    results: List[Dict[str, Any]] = Field(
        ..., 
        title="R√©sultats", 
        description="R√©sultats d√©taill√©s de la validation pour chaque mod√®le",
        example=[{
            "model_name": "dst_trustpilot",
            "model_version": "2",
            "accuracy": 0.82,
            "approved": True,
            "action_taken": "promoted_to_production"
        }]
    )
    saved_path: str = Field(
        ..., 
        title="Chemin de sauvegarde", 
        description="Chemin o√π les donn√©es trait√©es ont √©t√© sauvegard√©es",
        example="data/processed/processed_data_20250723_120000.csv"
    )

@app.post("/upload", tags=["Donn√©es"], summary="Upload de donn√©es d'entra√Ænement CSV")
@log_endpoint
async def upload_data(file: UploadFile = File(
    ..., 
    description="Fichier CSV contenant les avis clients √† traiter pour l'entra√Ænement. Doit inclure les colonnes 'Avis' et 'Note'."
)):
    """
    Endpoint pour uploader et traiter un fichier CSV d'avis clients.
    
    Le fichier doit contenir au minimum les colonnes 'Avis' et 'Note'.
    
    - 'Avis' : Texte de l'avis client
    - 'Note' : Note num√©rique (g√©n√©ralement de 1 √† 5)
    
    Returns:
        IngestionResponse: Informations sur le traitement effectu√©
    """
    # Cr√©ation d'un ID unique pour cet upload
    upload_id = str(uuid.uuid4())[:8]
    logger.info(f"[{upload_id}] R√©ception d'un fichier: {file.filename}, taille: {file.size} bytes")
    
    try:
        # V√©rification de l'extension
        if not file.filename.endswith('.csv'):
            logger.warning(f"[{upload_id}] Extension de fichier non valide: {file.filename}")
            raise HTTPException(status_code=400, detail="Le fichier doit √™tre au format CSV")
        
        # Cr√©ation d'un dossier temporaire pour stocker le fichier
        with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
            logger.info(f"[{upload_id}] Cr√©ation d'un fichier temporaire: {tmp_file.name}")
            content = await file.read()
            tmp_file.write(content)
            tmp_file.flush()
            logger.debug(f"[{upload_id}] Fichier temporaire cr√©√©: {tmp_file.name}, taille: {len(content)} bytes")
            
            # Cr√©ation du pipeline d'ingestion
            logger.info(f"[{upload_id}] Cr√©ation du pipeline d'ingestion pour donn√©es d'entra√Ænement")
            pipeline = DataIngestionPipeline(
                data_path=tmp_file.name,
                experiment_name="data_ingestion_api",
                is_validation_set=False
            )
            
            # Mesure du temps de traitement
            start_time = time.time()
            
            # Ex√©cution du pipeline
            logger.info(f"[{upload_id}] Ex√©cution du pipeline d'ingestion")
            processed_data = pipeline.run_pipeline()
            
            # Calcul du temps d'ex√©cution
            execution_time = time.time() - start_time
            logger.info(f"[{upload_id}] Pipeline ex√©cut√© en {execution_time:.3f}s - Lignes trait√©es: {len(processed_data)}")
            
            # Cr√©ation du dossier processed s'il n'existe pas
            logger.debug(f"[{upload_id}] Cr√©ation du dossier de sortie data/processed")
            os.makedirs('data/processed', exist_ok=True)
            
            # Sauvegarde des donn√©es trait√©es
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"data/processed/processed_data_{timestamp}.csv"
            logger.info(f"[{upload_id}] Sauvegarde des donn√©es trait√©es: {output_path}")
            processed_data.to_csv(output_path, index=False)
            
            # Calcul des statistiques
            logger.debug(f"[{upload_id}] Calcul des statistiques sur les donn√©es")
            stats = pipeline.get_data_stats(processed_data)
            logger.info(f"[{upload_id}] Statistiques: {len(processed_data)} lignes, note moyenne: {stats.get('avg_note', 'N/A')}")
            
            response = IngestionResponse(
                status="success",
                n_processed_rows=len(processed_data),
                stats=stats,
                saved_path=output_path
            )
            
            logger.info(f"[{upload_id}] Traitement termin√© avec succ√®s: {len(processed_data)} lignes sauvegard√©es dans {output_path}")
            return response
            
    except Exception as e:
        logger.error(f"[{upload_id}] Erreur lors du traitement du fichier: {str(e)}", exc_info=True)
        raise HTTPException(status_code=400, detail=str(e))
    finally:
        # Nettoyage du fichier temporaire
        if 'tmp_file' in locals():
            logger.debug(f"[{upload_id}] Nettoyage du fichier temporaire: {tmp_file.name}")
            os.unlink(tmp_file.name)

@app.post("/upload/validation", tags=["Donn√©es"], summary="Upload de donn√©es de validation CSV")
@log_endpoint
async def upload_validation_data(file: UploadFile = File(
    ..., 
    description="Fichier CSV contenant les avis clients √† utiliser comme donn√©es de validation. Doit inclure les colonnes 'Avis' et 'Note'."
)):
    """
    Endpoint pour uploader et traiter un fichier CSV d'avis clients sp√©cifiquement pour la validation des mod√®les.
    
    Le fichier doit contenir au minimum les colonnes 'Avis' et 'Note'.
    Ces donn√©es seront tagu√©es comme 'jdd validation' et utilis√©es pour √©valuer les mod√®les avant leur mise en production.
    
    - 'Avis' : Texte de l'avis client
    - 'Note' : Note num√©rique (g√©n√©ralement de 1 √† 5)
    
    Returns:
        IngestionResponse: Informations sur le traitement effectu√©
    """
    # Cr√©ation d'un ID unique pour cet upload
    upload_id = str(uuid.uuid4())[:8]
    logger.info(f"[{upload_id}] R√©ception d'un fichier de validation: {file.filename}, taille: {file.size} bytes")
    
    try:
        # V√©rification de l'extension
        if not file.filename.endswith('.csv'):
            logger.warning(f"[{upload_id}] Extension de fichier non valide: {file.filename}")
            raise HTTPException(status_code=400, detail="Le fichier doit √™tre au format CSV")
        
        # Cr√©ation d'un dossier temporaire pour stocker le fichier
        with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
            logger.info(f"[{upload_id}] Cr√©ation d'un fichier temporaire: {tmp_file.name}")
            content = await file.read()
            tmp_file.write(content)
            tmp_file.flush()
            logger.debug(f"[{upload_id}] Fichier temporaire cr√©√©: {tmp_file.name}, taille: {len(content)} bytes")
            
            # Cr√©ation du pipeline d'ingestion avec is_validation_set=True
            logger.info(f"[{upload_id}] Cr√©ation du pipeline d'ingestion pour donn√©es de validation")
            pipeline = DataIngestionPipeline(
                data_path=tmp_file.name,
                experiment_name="data_ingestion_api",
                is_validation_set=True
            )
            
            # Mesure du temps de traitement
            start_time = time.time()
            processed_data = pipeline.run_pipeline()
            processing_time = time.time() - start_time
            logger.info(f"[{upload_id}] Traitement effectu√© en {processing_time:.3f}s - {len(processed_data)} lignes")
            
            # Sauvegarde des donn√©es trait√©es
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"data/processed/validation_data_{timestamp}.csv"
            logger.info(f"[{upload_id}] Sauvegarde des donn√©es de validation: {output_path}")
            processed_data.to_csv(output_path, index=False)
            
            # Calcul des statistiques
            logger.debug(f"[{upload_id}] Calcul des statistiques sur les donn√©es")
            stats = pipeline.get_data_stats(processed_data)
            logger.info(f"[{upload_id}] Statistiques: {len(processed_data)} lignes, note moyenne: {stats.get('avg_note', 'N/A')}")
            
            response = IngestionResponse(
                status="success",
                n_processed_rows=len(processed_data),
                stats=stats,
                saved_path=output_path
            )
            
            logger.info(f"[{upload_id}] Traitement de donn√©es de validation termin√© avec succ√®s: {len(processed_data)} lignes sauvegard√©es dans {output_path}")
            return response
            
    except Exception as e:
        logger.error(f"[{upload_id}] Erreur lors du traitement du fichier de validation: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors du traitement du fichier: {str(e)}")
    finally:
        # Nettoyage du fichier temporaire
        if 'tmp_file' in locals():
            logger.debug(f"[{upload_id}] Nettoyage du fichier temporaire: {tmp_file.name}")
            os.unlink(tmp_file.name)

@app.get("/", tags=["G√©n√©ral"])
@log_endpoint
def read_root():
    """Point d'entr√©e de l'API"""
    logger.info("Acc√®s √† la racine de l'API")
    return {"message": "Bienvenue sur l'API de pr√©diction"}

@app.post("/predict/form", response_model=PredictionResponse, tags=["Pr√©diction"], summary="Pr√©diction via formulaire ‚ú®")
@log_endpoint
def predict_form(
    text: str = Form(
        "Ce produit est vraiment excellent, je le recommande vivement !", 
        description="Le texte de l'avis client pour lequel vous souhaitez pr√©dire le sentiment",
        example="Ce produit est vraiment excellent, je le recommande vivement !"
    ),
    model_name: Optional[str] = Form(
        "", 
        description="Nom du mod√®le √† utiliser pour la pr√©diction (laisser vide pour utiliser le mod√®le par d√©faut)",
        example="dst_trustpilot"
    ),
    model_version: Optional[str] = Form(
        "", 
        description="Version sp√©cifique du mod√®le √† utiliser (laisser vide pour utiliser la derni√®re version)",
        example="1"
    )
):
    """
    ‚úÖ Endpoint pour la classification de texte via formulaire (recommand√© pour les tests)
    
    Un exemple de texte est d√©j√† pr√©-rempli pour faciliter les tests.
    
    Permet de soumettre facilement :
    - **text**: Le texte de l'avis client √† analyser (pr√©-rempli avec un exemple)
    - **model_name** (optionnel): Laisser vide pour utiliser le mod√®le par d√©faut
    - **model_version** (optionnel): Laisser vide pour utiliser la derni√®re version
        
    Returns:
        PredictionResponse: Pr√©diction du mod√®le avec les d√©tails suivants :
            - prediction: 0 pour n√©gatif, 1 pour positif
            - probabilities: probabilit√©s pour chaque classe
            - sentiment: "n√©gatif" ou "positif" en texte
    """
    return _predict_internal(text, model_name, model_version)

@app.post("/predict", response_model=PredictionResponse, tags=["Pr√©diction"], summary="Pr√©diction via JSON")
def predict(request: PredictionRequest):
    """
    Endpoint pour la classification de texte via JSON (format standard)
    
    Pour une version avec formulaire, utilisez plut√¥t l'endpoint `/predict/form`
    
    Args:
        request (PredictionRequest): Requ√™te contenant le texte √† classifier
        
    Returns:
        PredictionResponse: Pr√©diction du mod√®le avec les d√©tails suivants :
            - prediction: 0 pour n√©gatif, 1 pour positif
            - probabilities: probabilit√©s pour chaque classe
            - sentiment: "n√©gatif" ou "positif" en texte
    """
    # Log manuel au lieu d'utiliser le d√©corateur
    request_id = str(uuid.uuid4())[:8]
    logger.info(f"[{request_id}] Re√ßu: POST /predict - Texte: {request.text[:30]}...")
    
    result = _predict_internal(request.text, request.model_name, request.model_version)
    
    logger.info(f"[{request_id}] Termin√©: POST /predict - Pr√©diction: {result.prediction}")
    return result

def _predict_internal(text: str, model_name: Optional[str] = None, model_version: Optional[str] = None):
    """
    Fonction interne de pr√©diction utilis√©e par les deux endpoints
    """
    # Cr√©ation d'un ID unique pour cette pr√©diction
    pred_id = str(uuid.uuid4())[:8]
    logger.info(f"[{pred_id}] Nouvelle demande de pr√©diction - Texte: '{text[:50]}...' - Mod√®le: {model_name or 'd√©faut'}, Version: {model_version or 'derni√®re'}")
    
    # Convertir les cha√Ænes vides en None pour le traitement correct des valeurs par d√©faut
    if model_name == "":
        model_name = None
        logger.debug(f"[{pred_id}] Nom du mod√®le vide converti en None")
    if model_version == "":
        model_version = None
        logger.debug(f"[{pred_id}] Version du mod√®le vide convertie en None")
    
    try:
        # Conversion du texte en s√©rie pandas
        logger.debug(f"[{pred_id}] Conversion du texte en s√©rie pandas")
        text_series = pd.Series([text])
        
        # Pr√©diction avec le mod√®le sp√©cifi√©
        logger.info(f"[{pred_id}] Obtention du service de pr√©diction")
        service = get_prediction_service(
            model_name=model_name,
            model_version=model_version
        )
        
        # Mesure du temps de pr√©diction
        start_time = time.time()
        logger.info(f"[{pred_id}] Ex√©cution de la pr√©diction")
        prediction_proba = service.predict_proba(text_series)
        execution_time = time.time() - start_time
        logger.info(f"[{pred_id}] Pr√©diction effectu√©e en {execution_time:.3f}s")
        
        # Le mod√®le retourne un tableau de forme (1, 2) avec des probabilit√©s
        if not isinstance(prediction_proba, np.ndarray) or prediction_proba.ndim != 2:
            logger.error(f"[{pred_id}] Format de pr√©diction invalide: {type(prediction_proba)}, shape: {getattr(prediction_proba, 'shape', 'N/A')}")
            raise ValueError("Format de pr√©diction invalide")
            
        # Extraire les probabilit√©s
        neg_proba, pos_proba = prediction_proba[0]
        logger.debug(f"[{pred_id}] Probabilit√©s: n√©gatif={neg_proba:.4f}, positif={pos_proba:.4f}")
        
        # D√©terminer la classe pr√©dite
        predicted_class = 1 if pos_proba > neg_proba else 0
        sentiment = "positif" if predicted_class == 1 else "n√©gatif"
        logger.info(f"[{pred_id}] Classe pr√©dite: {predicted_class} ({sentiment})")
        
        response = PredictionResponse(
            prediction=predicted_class,
            probabilities={
                "n√©gatif": float(neg_proba),
                "positif": float(pos_proba)
            },
            sentiment=sentiment
        )
        
        logger.info(f"[{pred_id}] Pr√©diction termin√©e avec succ√®s: {sentiment} (score: {max(neg_proba, pos_proba):.4f})")
        return response
    
    except Exception as e:
        logger.error(f"[{pred_id}] Erreur lors de la pr√©diction: {str(e)}", exc_info=True)
        raise HTTPException(status_code=400, detail=str(e))

@app.post("/train/form", response_model=TrainingResponse, tags=["Entra√Ænement"], summary="Entra√Ænement via formulaire ‚ú®")
@log_endpoint
async def train_model_form(
    run_id: Optional[str] = Form(
        "",
        description="ID du run MLflow contenant les donn√©es d'entra√Ænement (laisser vide pour utiliser le dernier run)",
        example="a1b2c3d4e5f6"
    ),
    model_name: Optional[str] = Form(
        "",
        description="Nom sous lequel enregistrer le nouveau mod√®le (laisser vide pour utiliser le nom par d√©faut)",
        example="mon_nouveau_modele"
    ),
    base_model_name: Optional[str] = Form(
        "",
        description="Nom du mod√®le √† utiliser comme base (laisser vide pour utiliser le mod√®le par d√©faut)",
        example="dst_trustpilot"
    ),
    base_model_version: Optional[str] = Form(
        "",
        description="Version du mod√®le de base √† utiliser (laisser vide pour utiliser la derni√®re version)",
        example="1"
    )
):
    """
    ‚úÖ Endpoint pour entra√Æner le mod√®le sur de nouvelles donn√©es via formulaire (recommand√© pour les tests).
    Utilise les donn√©es d'un run MLflow d'ingestion sp√©cifique ou le dernier run r√©ussi.
    
    Tous les champs sont optionnels et peuvent √™tre laiss√©s vides.
    
    Le formulaire permet de soumettre :
    - **run_id** (optionnel): Laisser vide pour utiliser le dernier run d'ingestion
    - **model_name** (optionnel): Laisser vide pour utiliser un nom g√©n√©r√© automatiquement
    - **base_model_name** (optionnel): Laisser vide pour utiliser le mod√®le par d√©faut
    - **base_model_version** (optionnel): Laisser vide pour utiliser la derni√®re version
        
    Returns:
        TrainingResponse: R√©sultat de l'entra√Ænement avec les m√©triques et informations
    """
    return await _train_internal(run_id, model_name, base_model_name, base_model_version)

@app.post("/train", response_model=TrainingResponse, tags=["Entra√Ænement"], summary="Entra√Ænement via JSON")
@log_endpoint
async def train_model(request: TrainingRequest):
    """
    Endpoint pour entra√Æner le mod√®le sur de nouvelles donn√©es via JSON.
    Utilise les donn√©es d'un run MLflow d'ingestion sp√©cifique ou le dernier run r√©ussi.
    
    Pour une version avec formulaire, utilisez plut√¥t l'endpoint `/train/form`
    
    Args:
        request (TrainingRequest): Requ√™te contenant optionnellement l'ID du run MLflow
        
    Returns:
        TrainingResponse: R√©sultat de l'entra√Ænement avec les m√©triques et informations
    """
    return await _train_internal(
        request.run_id, 
        request.model_name, 
        request.base_model_name, 
        request.base_model_version
    )

async def _train_internal(
    run_id: Optional[str] = None,
    model_name: Optional[str] = None,
    base_model_name: Optional[str] = None,
    base_model_version: Optional[str] = None
):
    """
    Fonction interne pour l'entra√Ænement du mod√®le utilis√©e par les deux endpoints
    """
    # Cr√©ation d'un ID unique pour cet entra√Ænement
    train_id = str(uuid.uuid4())[:8]
    logger.info(f"[{train_id}] Nouvelle demande d'entra√Ænement - Run ID: {run_id or 'Auto'}, Mod√®le: {model_name or 'Auto'}")
    
    # Convertir les cha√Ænes vides en None pour le traitement correct des valeurs par d√©faut
    if run_id == "":
        run_id = None
        logger.debug(f"[{train_id}] Run ID vide converti en None")
    if model_name == "":
        model_name = None
        logger.debug(f"[{train_id}] Nom du mod√®le vide converti en None")
    if base_model_name == "":
        base_model_name = None
        logger.debug(f"[{train_id}] Nom du mod√®le de base vide converti en None")
    if base_model_version == "":
        base_model_version = None
        logger.debug(f"[{train_id}] Version du mod√®le de base vide convertie en None")
        
    try:
        # Lancement de l'entra√Ænement
        logger.info(f"[{train_id}] D√©marrage de l'entra√Ænement{'avec run_id: ' + run_id if run_id else ''}")
        
        # Mesure du temps d'entra√Ænement
        start_time = time.time()
        
        metrics = train_model_function(
            run_id=run_id,
            model_name=model_name,
            base_model_name=base_model_name,
            base_model_version=base_model_version
        )
        
        # Calcul du temps d'entra√Ænement
        execution_time = time.time() - start_time
        logger.info(f"[{train_id}] Entra√Ænement termin√© en {execution_time:.3f}s")
        
        # Log des m√©triques obtenues
        logger.info(f"[{train_id}] M√©triques: Train accuracy={metrics['train_accuracy']:.4f}, Test accuracy={metrics['test_accuracy']:.4f}")
        
        # R√©cup√©ration du run MLflow actuel
        run = mlflow.get_run(run_id=metrics["run_id"])
        if not run:
            logger.error(f"[{train_id}] Impossible de r√©cup√©rer le run MLflow pour l'ID: {metrics['run_id']}")
            raise ValueError("Impossible de r√©cup√©rer le run MLflow")
            
        logger.info(f"[{train_id}] Mod√®le entra√Æn√© et enregistr√© - Run ID: {run.info.run_id}, Mod√®le: {metrics['model_name']}, Version: {metrics['model_version']}")
        
        return TrainingResponse(
            status="success",
            metrics={
                "train_accuracy": metrics["train_accuracy"],
                "test_accuracy": metrics["test_accuracy"]
            },
            run_id=run.info.run_id,
            data_path=metrics["data_path"],
            message="Mod√®le entra√Æn√© avec succ√®s",
            model_name=metrics["model_name"],
            model_version=metrics["model_version"]
        )
        
    except Exception as e:
        logger.error(f"[{train_id}] Erreur lors de l'entra√Ænement: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de l'entra√Ænement: {str(e)}"
        )

@app.post("/validate", response_model=ValidationResponse, tags=["Validation"], summary="Validation de mod√®le via JSON")
@log_endpoint
async def validate(request: ValidationRequest):
    """
    Endpoint pour valider un ou plusieurs mod√®les.
    
    Si model_name et model_version sont sp√©cifi√©s, valide uniquement ce mod√®le.
    Sinon, valide tous les mod√®les en attente de validation (marqu√©s "√† valider").
    
    Si auto_approve=True, les mod√®les qui passent la validation sont automatiquement promus en production.
    
    Args:
        request (ValidationRequest): Param√®tres de validation
        
    Returns:
        ValidationResponse: R√©sultats de la validation
    """
    validation_id = str(uuid.uuid4())[:8]
    logger.info(f"[{validation_id}] Nouvelle demande de validation - Mod√®le: {request.model_name or 'tous'}, "
               f"Version: {request.model_version or 'toutes'}, Auto-approbation: {request.auto_approve}")
    
    # Ex√©cution de la validation
    result = validate_model(
        model_name=request.model_name,
        model_version=request.model_version,
        approve=request.auto_approve,
        threshold=request.threshold
    )
    
    logger.info(f"[{validation_id}] Validation termin√©e - {result['models_validated']} mod√®les valid√©s")
    return result

@app.post("/validate/form", response_model=ValidationResponse, tags=["Validation"], summary="Validation de mod√®le via formulaire ‚ú®")
@log_endpoint
async def validate_form(
    model_name: Optional[str] = Form(
        "", 
        description="Nom du mod√®le √† valider (laisser vide pour tous les mod√®les en attente)",
        example="dst_trustpilot"
    ),
    model_version: Optional[str] = Form(
        "", 
        description="Version du mod√®le √† valider (obligatoire si un nom de mod√®le est sp√©cifi√©)",
        example="2"
    ),
    auto_approve: bool = Form(
        False, 
        description="Si coch√©, les mod√®les valid√©s seront automatiquement promus en production",
        example=False
    ),
    threshold: Optional[float] = Form(
        None, 
        description="Seuil d'accuracy pour la validation (utilise la valeur par d√©faut si non sp√©cifi√©)",
        example=0.75
    )
):
    """
    Endpoint pour valider un ou plusieurs mod√®les via formulaire.
    
    Si model_name et model_version sont sp√©cifi√©s, valide uniquement ce mod√®le.
    Sinon, valide tous les mod√®les en attente de validation (marqu√©s "√† valider").
    
    Si auto_approve=True, les mod√®les qui passent la validation sont automatiquement promus en production.
    
    Returns:
        ValidationResponse: R√©sultats de la validation
    """
    # Convertir les cha√Ænes vides en None
    if model_name == "":
        model_name = None
    if model_version == "":
        model_version = None
    
    validation_id = str(uuid.uuid4())[:8]
    logger.info(f"[{validation_id}] Nouvelle demande de validation (formulaire) - Mod√®le: {model_name or 'tous'}, "
               f"Version: {model_version or 'toutes'}, Auto-approbation: {auto_approve}")
    
    # Ex√©cution de la validation
    result = validate_model(
        model_name=model_name,
        model_version=model_version,
        approve=auto_approve,
        threshold=threshold
    )
    
    logger.info(f"[{validation_id}] Validation termin√©e - {result['models_validated']} mod√®les valid√©s")
    return result

@app.post("/promote/{model_name}/{model_version}", response_model=ValidationResponse, tags=["Validation"], summary="Promotion de mod√®le en production")
@log_endpoint
async def promote_model(
    model_name: str = Path(..., description="Nom du mod√®le √† promouvoir en production"),
    model_version: str = Path(..., description="Version du mod√®le √† promouvoir en production")
):
    """
    Endpoint pour valider et promouvoir directement un mod√®le en production.
    
    Le mod√®le sera d'abord valid√© et, s'il passe la validation avec succ√®s, sera promu en production.
    
    Args:
        model_name: Nom du mod√®le √† promouvoir
        model_version: Version du mod√®le √† promouvoir
        
    Returns:
        ValidationResponse: R√©sultat de la validation et promotion
    """
    promotion_id = str(uuid.uuid4())[:8]
    logger.info(f"[{promotion_id}] Demande de promotion directe - Mod√®le: {model_name}, Version: {model_version}")
    
    # Validation et promotion
    result = validate_and_promote_model(model_name, model_version)
    
    if result['results'] and result['results'][0].get('action_taken') == 'promoted_to_production':
        logger.info(f"[{promotion_id}] Mod√®le {model_name} v{model_version} promu en production avec succ√®s")
    else:
        logger.warning(f"[{promotion_id}] √âchec de la promotion du mod√®le {model_name} v{model_version}")
    
    return result

if __name__ == "__main__":
    import uvicorn
    
    # Le logging est d√©j√† initialis√© au d√©but du fichier
    logger.info("D√©marrage du serveur API")
    
    # D√©marrage du serveur
    uvicorn.run(app, host="0.0.0.0", port=8042)  # Port 8042 pour correspondre au Dockerfile
